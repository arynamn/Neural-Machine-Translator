{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54ggsIRvpNvx"
   },
   "source": [
    "## ENCODER DECODER NETWORK WITH ATTENTION AND TEACHER FORCING\n",
    "\n",
    "**References:**\n",
    "\n",
    "Tutorials Given in Competition Document : [Competetion Link](https://docs.google.com/document/d/1p74wG-bECCgbpyq5x_x2QJrf5RSf9FnMLGSAiyUkHLo/edit)\n",
    "\n",
    "PyTorch NMT Tutorial : [Pytorch NMT](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html)\n",
    "\n",
    "Github Page : To understand batch Processing in PyTorch [Github Pengyuchen](https://github.com/pengyuchen/PyTorch-Batch-Seq2seq)\n",
    "\n",
    "Referred Few Stackoverflow Links for few Regex examples and for some bugs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zm2HohCVJIKy"
   },
   "source": [
    "# **FUNCTIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34891,
     "status": "ok",
     "timestamp": 1617528300092,
     "user": {
      "displayName": "Aman Aryan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjK8COdTMVIts9k8ZQiYXt_e98hss7FWnXQm15B=s64",
      "userId": "06138380680336854578"
     },
     "user_tz": -330
    },
    "id": "U9KkhcYfEeuH",
    "outputId": "37f7aaaf-b75f-45ad-b697-e704f1bc7827"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import  drive\n",
    "drive.mount('/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YkqUlmpnCNw-"
   },
   "source": [
    "## LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XE346yhTt_vl"
   },
   "outputs": [],
   "source": [
    "location = r\"/drive/My Drive/Files/\"\n",
    "INDIC_NLP_LIB_HOME = location + \"indic_nlp_library\"\n",
    "INDIC_NLP_RESOURCES = location + \"indic_nlp_resources\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j9GYWzxIvQLf"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'{}'.format(INDIC_NLP_LIB_HOME))\n",
    "from indicnlp import common\n",
    "common.set_resources_path(INDIC_NLP_RESOURCES)\n",
    "from indicnlp import loader\n",
    "loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 49390,
     "status": "ok",
     "timestamp": 1617528314639,
     "user": {
      "displayName": "Aman Aryan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjK8COdTMVIts9k8ZQiYXt_e98hss7FWnXQm15B=s64",
      "userId": "06138380680336854578"
     },
     "user_tz": -330
    },
    "id": "6sFoIG0IL5Gu",
    "outputId": "d14d4427-58bf-49d3-cb9e-8ec56a878fd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Morfessor\n",
      "  Downloading https://files.pythonhosted.org/packages/39/e6/7afea30be2ee4d29ce9de0fa53acbb033163615f849515c0b1956ad074ee/Morfessor-2.0.6-py3-none-any.whl\n",
      "Installing collected packages: Morfessor\n",
      "Successfully installed Morfessor-2.0.6\n"
     ]
    }
   ],
   "source": [
    "!pip install Morfessor\n",
    "import re\n",
    "import string\n",
    "import spacy\n",
    "import tqdm.notebook as tq\n",
    "nlpen = spacy.load(\"en_core_web_sm\")\n",
    "import random\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from indicnlp.tokenize import sentence_tokenize\n",
    "from indicnlp.tokenize import indic_tokenize\n",
    "from indicnlp.transliterate.unicode_transliterate import UnicodeIndicTransliterator\n",
    "from indicnlp.transliterate.unicode_transliterate import ItransTransliterator\n",
    "from indicnlp.normalize.indic_normalize import IndicNormalizerFactory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eOV8__452nrJ"
   },
   "source": [
    "## TEXT PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8s4-n71ApEaD"
   },
   "outputs": [],
   "source": [
    "english_nums = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "hindi_nums =   ['०', '१', '२', '३', '४', '५', '६', '७', '८', '९']\n",
    "\n",
    "def clean_string( instr ):\n",
    "  instr = instr.lower()\n",
    "  instr = instr.replace(u'[', ' ')\n",
    "  instr = instr.replace(u']', ' ')\n",
    "  instr = instr.replace(u'{', ' ')\n",
    "  instr = instr.replace(u'}', ' ')\n",
    "  instr = instr.replace(u'(', ' ')\n",
    "  instr = instr.replace(u')', ' ')\n",
    "  instr = instr.replace(u'...', ' ')\n",
    "  instr = instr.replace(u'..', ' ')\n",
    "  instr = instr.replace(u'-', ' ')\n",
    "  instr = instr.replace(u',', ' ')\n",
    "  instr = instr.replace(u'\"', ' ')\n",
    "  instr = re.sub(' +',' ', instr)\n",
    "  return instr\n",
    "  \n",
    "def preprocess_hindi( instr ):\n",
    "  factory    = IndicNormalizerFactory()\n",
    "  normalizer = factory.get_normalizer(\"hi\",remove_nuktas=True)\n",
    "  instr      = normalizer.normalize(instr)\n",
    "\n",
    "  instr      = clean_string( instr )\n",
    "  #instr = instr.replace(u'॥', '')\n",
    "  for nums in hindi_nums:\n",
    "    instr    = instr.replace(nums, nums + ' ')\n",
    "\n",
    "  instr      = ItransTransliterator.from_itrans( instr , 'hi')  \n",
    "  instr      = re.sub(' +',' ', instr)\n",
    "  instr      = ItransTransliterator.from_itrans( instr , 'hi')\n",
    "  instr      = instr.strip() #sentence_tokenize.sentence_split(instr, lang='hi')\n",
    "  \n",
    "  return instr\n",
    "\n",
    "def preprocess_english( instr ):\n",
    "  instr = clean_string(instr)\n",
    "\n",
    "  instr = instr.replace(\"’\", \"'\")\n",
    "  instr = instr.replace(\"n\\'t\", \" not\")\n",
    "  instr = instr.replace(\"'re\" , \" are\")\n",
    "  instr = instr.replace(\"'ve\" , \" have\")\n",
    "  instr = instr.replace(\"'s\"  , \" is\")\n",
    "  instr = instr.replace(\"'ll\" , \" will\")\n",
    "  instr = instr.replace(\"'m\" , \" am\")\n",
    "  #instr = re.sub(r'[^\\w\\s\\\\d]' , \" \" , instr)\n",
    "  #instr = re.sub(r'[\\d]' , ' ' , instr)\n",
    "\n",
    "  for nums in english_nums:\n",
    "    instr    = instr.replace(nums, nums + ' ')\n",
    "  instr = re.sub(' +',' ', instr)\n",
    "  instr = instr.strip()\n",
    "\n",
    "  return instr\n",
    "\n",
    "def get_hindi_tokens(sentence):\n",
    "  return indic_tokenize.trivial_tokenize(sentence)\n",
    "\n",
    "def get_english_tokens(sentence):\n",
    "  tokens = []\n",
    "  tokstr = nlpen(sentence)\n",
    "  for token in tokstr:\n",
    "    tokens.append(token.text)\n",
    "  return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7xMHlxgWiAEk"
   },
   "outputs": [],
   "source": [
    "def process_pairs(df, load_from_file = 0, location = ''):\n",
    "  if( load_from_file == 0):\n",
    "    pairs = []\n",
    "    pairs_tokens = []\n",
    "    for i in tq.tqdm( df.index ):\n",
    "      hinsen  = df['hindi'][i]\n",
    "      hsent   = preprocess_hindi( hinsen )\n",
    "      htokens = get_hindi_tokens(hsent)\n",
    "\n",
    "      engsen  = df['english'][i]\n",
    "      esent   = preprocess_english( engsen )\n",
    "      etokens = get_english_tokens(esent)\n",
    "\n",
    "      pairs.append( [hsent, esent] )\n",
    "      pairs_tokens.append( [htokens, etokens] )\n",
    "\n",
    "    with open(location + r'pairs.pickle', 'wb') as handle:\n",
    "        pickle.dump(pairs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open(location + r'pairs_tokens.pickle', 'wb') as handle:\n",
    "        pickle.dump(pairs_tokens, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    return pairs, pairs_tokens\n",
    "  else:\n",
    "    with open(location + r'pairs.pickle', 'rb') as handle:\n",
    "        pairs = pickle.load(handle)\n",
    "    with open(location + r'pairs_tokens.pickle', 'rb') as handle:\n",
    "        pairs_tokens = pickle.load(handle)\n",
    "    return pairs, pairs_tokens  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JfKCjT9t2Uce"
   },
   "source": [
    "## LANGUAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pkvN-M2T2OwM"
   },
   "outputs": [],
   "source": [
    "START_TOKEN = 0\n",
    "END_TOKEN = 1\n",
    "PAD_TOKEN = 2\n",
    "\n",
    "class Language:\n",
    "  def __init__(self, name):\n",
    "    self.name = name\n",
    "    self.word2index = {}\n",
    "    self.word2count = {}\n",
    "    self.index2word = {}\n",
    "    self.num_words = 3\n",
    "    self.word2index['START_TOKEN'] = START_TOKEN\n",
    "    self.index2word['END_TOKEN'] = END_TOKEN\n",
    "    self.index2word['PAD_TOKEN'] = PAD_TOKEN\n",
    "    self.index2word[START_TOKEN] = 'START_TOKEN'\n",
    "    self.index2word[END_TOKEN] = 'END_TOKEN'\n",
    "    self.index2word[PAD_TOKEN] = 'PAD_TOKEN'\n",
    "\n",
    "  def addWord(self, word):\n",
    "    if word in self.word2index:\n",
    "      self.word2count[word] = self.word2count[word] + 1\n",
    "    else:\n",
    "      self.word2count[word] = 1\n",
    "      self.word2index[word] = self.num_words\n",
    "      self.index2word[self.num_words] = word\n",
    "      self.num_words = self.num_words + 1\n",
    "  \n",
    "  def addSentence(self, sentence_tokens):\n",
    "      for word in sentence_tokens:\n",
    "        self.addWord(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8S24eNCE2Oyb"
   },
   "outputs": [],
   "source": [
    "def generate_language( pairs_tokens ):\n",
    "    hindi   = Language('hindi')\n",
    "    english = Language('english')\n",
    "    for i in tq.tqdm( range(len(pairs_tokens)) ):\n",
    "      hindi.addSentence(pairs_tokens[i][0])\n",
    "      english.addSentence(pairs_tokens[i][1])\n",
    "    return hindi, english"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-IHLiyXjNOM5"
   },
   "source": [
    "PROCESS TEXT TO TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nFD_H_CgKBFI"
   },
   "outputs": [],
   "source": [
    "def get_filitered_data(max_length, pairs, pairs_tokens):\n",
    "  fil_pairs = []\n",
    "  fil_pairs_tokens = []\n",
    "  for i in  range( len(pairs_tokens)) :\n",
    "    if( len(pairs_tokens[i][0] ) < max_length and len(pairs_tokens[i][1]) < max_length ):\n",
    "      fil_pairs.append( pairs[i] )\n",
    "      fil_pairs_tokens.append( pairs_tokens[i] )\n",
    "  return fil_pairs, fil_pairs_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_KiyGuO121HM"
   },
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, tokens, max_length):\n",
    "  indexes = []\n",
    "  indexes.append(START_TOKEN)\n",
    "  for word in tokens:\n",
    "    if word in lang.word2index.keys():\n",
    "      indexes.append( lang.word2index[word] )\n",
    "    else:\n",
    "      indexes.append( random.randint(2, lang.num_words))\n",
    "  indexes = indexes[0:max_length-1]\n",
    "  indexes.append(END_TOKEN)\n",
    "  indexes.extend( [PAD_TOKEN]*( max_length - len(indexes)))\n",
    "  return indexes\n",
    "\n",
    "def tensorFromSentence(lang, sentence, max_length):\n",
    "  indexes = indexesFromSentence(lang, sentence, max_length)\n",
    "  return torch.tensor(indexes, dtype=torch.long, device=device)\n",
    "\n",
    "def tensorsFromPair(pairs, input_lang, output_lang, max_length):\n",
    "  res_pairs = []\n",
    "  for pair in pairs:\n",
    "    input_tensor  = tensorFromSentence(input_lang, pair[0], max_length)\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1], max_length)\n",
    "    res_pairs.append( (input_tensor, target_tensor) )\n",
    "  return res_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wpIHes6i3cuR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZTFkvFITItSA"
   },
   "source": [
    "## NEURAL MACHINE TRANSLATOR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pxSdrKcBUOOn"
   },
   "source": [
    "LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 60312,
     "status": "ok",
     "timestamp": 1617528325615,
     "user": {
      "displayName": "Aman Aryan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjK8COdTMVIts9k8ZQiYXt_e98hss7FWnXQm15B=s64",
      "userId": "06138380680336854578"
     },
     "user_tz": -330
    },
    "id": "3Z1jYXWzCqpa",
    "outputId": "939bd169-7d8b-4774-b66f-d23a98ab519a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4MB 7.3MB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.7/dist-packages (from nltk) (2019.12.20)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.41.1)\n",
      "Building wheels for collected packages: nltk\n",
      "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for nltk: filename=nltk-3.5-cp37-none-any.whl size=1434673 sha256=64b04de7675d442c12e664cd2a218ad4ab6c67d8987f71c6e27adf6d7eac1939\n",
      "  Stored in directory: /root/.cache/pip/wheels/ae/8c/3f/b1fe0ba04555b08b57ab52ab7f86023639a526d8bc8d384306\n",
      "Successfully built nltk\n",
      "Installing collected packages: nltk\n",
      "  Found existing installation: nltk 3.2.5\n",
      "    Uninstalling nltk-3.2.5:\n",
      "      Successfully uninstalled nltk-3.2.5\n",
      "Successfully installed nltk-3.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "!pip install -U nltk\n",
    "import nltk\n",
    "import sys\n",
    "nltk.download('wordnet')\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.meteor_score import single_meteor_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S7q0i3jQIYYy"
   },
   "source": [
    "###### ENCODER and DECODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ibd0funOIVy-"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden, batch_size=1):\n",
    "        embedded = self.embedding(input).view(1, batch_size, self.hidden_size)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self, batch_size=1):\n",
    "        return torch.zeros(1, batch_size, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bvKT-boqIb-L"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, max_length):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.max_length = max_length\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden, batch_size=1):\n",
    "        embed = self.embedding(input).view(1, batch_size, self.hidden_size)\n",
    "        output, hidden = self.gru(embed, hidden)\n",
    "        output = self.out(output)\n",
    "        preds = self.softmax(output[0])\n",
    "        return preds, hidden\n",
    "\n",
    "\n",
    "    def initHidden(self, batch_size=1):\n",
    "        return torch.zeros(1, batch_size, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WcrhHwoc03gH"
   },
   "source": [
    "##### SEQUENCE 2 SEQUENCE + Teacher Forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2XOqKk6z02WY"
   },
   "outputs": [],
   "source": [
    "class seq2seq(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size, max_length):\n",
    "        super(seq2seq, self).__init__()\n",
    "        self.input_size  = input_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.encoder = Encoder(input_size, hidden_size).to(device)\n",
    "        self.decoder = Decoder(hidden_size, output_size, max_length).to(device)\n",
    "\n",
    "\n",
    "\n",
    "    def train_model(self, train_data, num_epoch ):\n",
    "        encoder_optim = optim.Adam(self.encoder.parameters(), lr = 0.01)\n",
    "        decoder_optim = optim.Adam(self.decoder.parameters(), lr = 0.01)\n",
    "        lossfn = nn.NLLLoss()\n",
    "\n",
    "        history = []\n",
    "        for epoch in (range(num_epoch)):\n",
    "            print('\\n Epoch  : ', epoch)\n",
    "\n",
    "            total_loss = 0\n",
    "\n",
    "            for bin, bout in tq.tqdm(train_data):\n",
    "                batch_size     = bin.size()[0]\n",
    "                input  = bin.transpose(0,1)\n",
    "                output = bout.transpose(0,1)\n",
    "                inlen  = input.size()[0]\n",
    "                outlen = output.size()[0]\n",
    "\n",
    "                encoder_hidden = self.encoder.initHidden(batch_size = batch_size)\n",
    "                encoder_optim.zero_grad()\n",
    "                decoder_optim.zero_grad()\n",
    "\n",
    "                loss = 0\n",
    "                encoder_outputs = torch.zeros(self.max_length, batch_size, self.encoder.hidden_size, device = device)\n",
    "                for ei in range(inlen):\n",
    "                    enc_output, encoder_hidden = self.encoder(input[ei],encoder_hidden, batch_size =batch_size)\n",
    "                    encoder_outputs[ei]        = enc_output[0]\n",
    "\n",
    "                decoder_input = torch.tensor([START_TOKEN]*batch_size, device=device)\n",
    "                decoder_hidden = encoder_hidden\n",
    "                # TEACHER FORCING\n",
    "                if random.random() < 0.5 :\n",
    "                  for di in range(outlen):\n",
    "                      decoder_output, decoder_hidden = self.decoder(\n",
    "                          decoder_input, decoder_hidden, batch_size= batch_size)\n",
    "                      decoder_input      = output[di]\n",
    "                      loss               = loss + lossfn( decoder_output, output[di])\n",
    "                else:\n",
    "                  for di in range(outlen):\n",
    "                      decoder_output, decoder_hidden = self.decoder(\n",
    "                          decoder_input, decoder_hidden, batch_size= batch_size)\n",
    "                      topvalue, topindex = decoder_output.data.topk(1)\n",
    "                      decoder_input      = topindex.squeeze().detach()\n",
    "                      loss               = loss + lossfn( decoder_output, output[di])\n",
    "\n",
    "                total_loss = total_loss + loss.item()\n",
    "\n",
    "                loss.backward()\n",
    "                encoder_optim.step()\n",
    "                decoder_optim.step()\n",
    "\n",
    "            history.append( total_loss / len(train_data))\n",
    "        return history\n",
    "          \n",
    "        \n",
    "    def predict_sentence(self, sentence, input_lang, output_lang):\n",
    "        with torch.no_grad():\n",
    "            input   = tensorFromSentence(input_lang, sentence, self.max_length)\n",
    "            inlen   = input.size()[0]\n",
    "            if inlen > self.max_length:\n",
    "              inlen = self.max_length\n",
    "\n",
    "            enc_hidden = self.encoder.initHidden(1)\n",
    "            enc_outputs = torch.zeros(self.max_length, self.encoder.hidden_size, device=device)\n",
    "            \n",
    "            for i in range(inlen):\n",
    "                enc_output, enc_hidden = self.encoder(input[i], enc_hidden)\n",
    "                enc_outputs[i]         = enc_outputs[i] + enc_output[0, 0]\n",
    "\n",
    "            dec_input      = torch.tensor([[START_TOKEN]], device=device)\n",
    "            dec_hidden     = enc_hidden\n",
    "            dec_words = []\n",
    "            \n",
    "            for i in range(self.max_length):\n",
    "              dec_output, dec_hidden = self.decoder( dec_input, dec_hidden , batch_size = 1)\n",
    "              maxval, maxindex = dec_output.data.topk(1)\n",
    "              dec_input = maxindex.squeeze().detach()\n",
    "\n",
    "              if(maxindex.item() == END_TOKEN):\n",
    "                dec_words.append('END_TOKEN')\n",
    "                break\n",
    "              else:\n",
    "                dec_words.append( output_lang.index2word[maxindex.item()] )\n",
    "          \n",
    "        return dec_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NXoK92_1o4Ez"
   },
   "source": [
    "PERFORMANCE EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hvQPdkMtov-L"
   },
   "outputs": [],
   "source": [
    "def make_sentence(tokens):\n",
    "  str = ''\n",
    "  for x in tokens:\n",
    "    if x not in ['START_TOKEN', 'END_TOKEN', 'PAD_TOKEN']:\n",
    "      str = str + ' ' + x\n",
    "  return re.sub('(?<=\\d)+ (?=\\d)+', '', str)[1:]\n",
    "\n",
    "\n",
    "def get_bleu_score(model, pairs, inlang, outlang):\n",
    "\n",
    "  total_num = len(pairs)\n",
    "  total_bleu_scores = 0\n",
    "  total_meteor_scores = 0\n",
    "  \n",
    "  for i in tq.tqdm( range(total_num) ):\n",
    "    output    = make_sentence ( model.predict_sentence(pairs[i][0], inlang, outlang) )\n",
    "    original  = make_sentence(pairs[i][1])\n",
    "    total_bleu_scores   += sentence_bleu([output.split(\" \")], original.split(\" \"))\n",
    "    total_meteor_scores += single_meteor_score(output, original)\n",
    "\n",
    "  bleu_result = total_bleu_scores/total_num\n",
    "  meteor_result = total_meteor_scores/total_num\n",
    "  \n",
    "  print()\n",
    "  print(\"bleu score: \",bleu_result)\n",
    "  print(\"meteor score: \",meteor_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SFtWOWbbsQwS"
   },
   "source": [
    "# **EXECUTION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OWWqvluwXPMG"
   },
   "source": [
    "READ AND PROCESS FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bi-YuD2xMLss"
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KF2PDfoyrush"
   },
   "outputs": [],
   "source": [
    "data_location = location + 'NMT/'\n",
    "model_location = location + 'NMT/NMT_GRUTF/'\n",
    "df = pd.read_csv(data_location+'train.csv',  index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CVBTJ9xE6eUW"
   },
   "outputs": [],
   "source": [
    "pairs, tokens = process_pairs(df, load_from_file=1, location = data_location + 'DataPairs/')\n",
    "train_pairs, test_pairs, train_tokens, test_tokens = train_test_split( pairs, tokens, test_size = 0.2, shuffle = True, random_state = 200)\n",
    "fil_train, fil_train_tokens = get_filitered_data( MAX_LENGTH - 2, train_pairs, train_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gz-s9YulXTuY"
   },
   "source": [
    "GENERATE LANGUAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "71fc56199ac44a2280ffe553d19a3e77",
      "0929e0ee656f4ade8f5af724746dfab2",
      "42c7157149e84f79a85326691352b2a8",
      "0fca71f0ec744dee823d449400815b86",
      "e7ed4b2db0bd4401bf0c01d40944a9f0",
      "dc0ee376dff14a96a46a044d27ed7195",
      "14fe0db99f234f36b8e148bd0a9229bc",
      "112d318996a44ac2b2535809b6c7f48f"
     ]
    },
    "executionInfo": {
     "elapsed": 65562,
     "status": "ok",
     "timestamp": 1617528330925,
     "user": {
      "displayName": "Aman Aryan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjK8COdTMVIts9k8ZQiYXt_e98hss7FWnXQm15B=s64",
      "userId": "06138380680336854578"
     },
     "user_tz": -330
    },
    "id": "NXybCQuygy9T",
    "outputId": "dd9ebddb-9dd9-4d70-fc9e-fb8ca90baef1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71fc56199ac44a2280ffe553d19a3e77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=81857.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "hindi, english = generate_language(train_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eUTkfpuxXXlI"
   },
   "source": [
    "GET TENSORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ww5AxnJ1r6rK"
   },
   "outputs": [],
   "source": [
    "train_tensors = tensorsFromPair(fil_train_tokens, hindi, english, MAX_LENGTH)\n",
    "train_loader = torch.utils.data.DataLoader(train_tensors, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D3zinlYyXay_"
   },
   "source": [
    "TRAIN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6KR75SsUXxE1"
   },
   "outputs": [],
   "source": [
    "hidden_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FxPgfDvYYr30"
   },
   "outputs": [],
   "source": [
    "model2 = seq2seq(hindi.num_words + 1, english.num_words + 1, hidden_size, MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VEG2GbQDalME"
   },
   "outputs": [],
   "source": [
    "model2.train_model(train_data= train_loader, num_epoch= 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1coUVIFu68Oj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GidWU1rMXdE-"
   },
   "source": [
    "SAVE / LOAD MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cdoodl3BQuVX"
   },
   "outputs": [],
   "source": [
    "torch.save(model2.state_dict(), model_location + 'gru_dict_200')\n",
    "torch.save(model2, model_location + 'gru_200')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1315,
     "status": "ok",
     "timestamp": 1617535209186,
     "user": {
      "displayName": "Aman Aryan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjK8COdTMVIts9k8ZQiYXt_e98hss7FWnXQm15B=s64",
      "userId": "06138380680336854578"
     },
     "user_tz": -330
    },
    "id": "UU_Bd47QsiRu",
    "outputId": "733c146a-a715-4904-9e68-20da6f1ad8c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "seq2seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(40447, 256)\n",
       "    (gru): GRU(256, 256)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(29686, 256)\n",
       "    (gru): GRU(256, 256)\n",
       "    (out): Linear(in_features=256, out_features=29686, bias=True)\n",
       "    (softmax): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = seq2seq(hindi.num_words + 1, english.num_words + 1, hidden_size, MAX_LENGTH)\n",
    "model.load_state_dict( torch.load(model_location + 'gru_dict_200', map_location=torch.device('cpu')))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gOyOr8EeXqLo"
   },
   "source": [
    "EVALUATE PERFORMANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aGKhcq18XC3h"
   },
   "outputs": [],
   "source": [
    "get_bleu_score(model2, test_tokens, hindi, english)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wd6jSg0bXg1a"
   },
   "source": [
    "# USE MODEL FOR TRANSLATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EmC5MWcQXmbH"
   },
   "outputs": [],
   "source": [
    "week1 = pd.read_csv(data_location+'Weekly Data/Week1/week1.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EAmOtFd2hlU1"
   },
   "outputs": [],
   "source": [
    "week1_processed = []\n",
    "week1_tensors = []\n",
    "for x in  week1['hindi']:\n",
    "  t = get_hindi_tokens(preprocess_hindi(x))\n",
    "  week1_processed.append(t)\n",
    "  week1_tensors.append( tensorFromSentence(hindi, t, MAX_LENGTH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "32e8ee6a0ab14f8aa53a685457fc01fa",
      "362bd8d7204445e1a00d9b64e5ec6cc6",
      "ed35a8718abb464d9fb0776874487e4c",
      "b15bce8e8b4748958b0799ea3a96e692",
      "0445ffb9d12e4e8bab8b139ae4e428e4",
      "e7ff3ddb815244a59883f9261d1d5ad6",
      "3cf390bba16d4d199979678ede175b13",
      "33ef3d3746f74453850b1ee475763ebe"
     ]
    },
    "executionInfo": {
     "elapsed": 46499,
     "status": "ok",
     "timestamp": 1617535258783,
     "user": {
      "displayName": "Aman Aryan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjK8COdTMVIts9k8ZQiYXt_e98hss7FWnXQm15B=s64",
      "userId": "06138380680336854578"
     },
     "user_tz": -330
    },
    "id": "DRsRuWQT1i7l",
    "outputId": "a121c42e-ffc3-4d8e-f689-8b7eef6d82bb"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32e8ee6a0ab14f8aa53a685457fc01fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5000.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "translated_tokens = []\n",
    "for i in tq.tqdm( range(len(week1_tensors)) ):\n",
    "  translated_tokens.append( model.predict_sentence( week1_tensors[i], hindi, english) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IXcs_EECan0d"
   },
   "outputs": [],
   "source": [
    "translated_texts = []\n",
    "for t in translated_tokens:\n",
    "  translated_texts.append( make_sentence(t ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mDufBeCJXw1f"
   },
   "outputs": [],
   "source": [
    "with open(data_location + 'Weekly Data/Week1/grutf.txt', 'w') as f:\n",
    "    for item in translated_texts:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uGXG3VGnZbxr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "frk9g3E8r8X4"
   },
   "outputs": [],
   "source": [
    "#torch.save( tmodel.state_dict(), model_location + 'gru_dict_100')\n",
    "#torch.save(model, location+ 'gru_enc_dec')\n",
    "\n",
    "#tmodel = torch.load(model_location+ 'gru_100')\n",
    "#tmodel.eval()\n",
    "\n",
    "#tq.tqdm._instances.clear()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "zm2HohCVJIKy",
    "YkqUlmpnCNw-",
    "eOV8__452nrJ",
    "JfKCjT9t2Uce",
    "ZTFkvFITItSA",
    "pxSdrKcBUOOn",
    "S7q0i3jQIYYy",
    "cQX6MBtpIiYi",
    "WcrhHwoc03gH",
    "NXoK92_1o4Ez",
    "OWWqvluwXPMG",
    "Gz-s9YulXTuY",
    "eUTkfpuxXXlI",
    "D3zinlYyXay_",
    "GidWU1rMXdE-",
    "gOyOr8EeXqLo"
   ],
   "name": "NMT_GRU_TF_ED.ipynb",
   "provenance": [
    {
     "file_id": "1I_Bo6Fo3_crelsSkQmYhMYWpfpYRnyeF",
     "timestamp": 1617518265937
    },
    {
     "file_id": "1OVzSFF2WWKLlGLDmMwQCTPq0UqiHMZsw",
     "timestamp": 1617169641987
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0445ffb9d12e4e8bab8b139ae4e428e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "0929e0ee656f4ade8f5af724746dfab2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0fca71f0ec744dee823d449400815b86": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_112d318996a44ac2b2535809b6c7f48f",
      "placeholder": "​",
      "style": "IPY_MODEL_14fe0db99f234f36b8e148bd0a9229bc",
      "value": " 81857/81857 [00:11&lt;00:00, 6953.14it/s]"
     }
    },
    "112d318996a44ac2b2535809b6c7f48f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "14fe0db99f234f36b8e148bd0a9229bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "32e8ee6a0ab14f8aa53a685457fc01fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ed35a8718abb464d9fb0776874487e4c",
       "IPY_MODEL_b15bce8e8b4748958b0799ea3a96e692"
      ],
      "layout": "IPY_MODEL_362bd8d7204445e1a00d9b64e5ec6cc6"
     }
    },
    "33ef3d3746f74453850b1ee475763ebe": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "362bd8d7204445e1a00d9b64e5ec6cc6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3cf390bba16d4d199979678ede175b13": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "42c7157149e84f79a85326691352b2a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dc0ee376dff14a96a46a044d27ed7195",
      "max": 81857,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e7ed4b2db0bd4401bf0c01d40944a9f0",
      "value": 81857
     }
    },
    "71fc56199ac44a2280ffe553d19a3e77": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_42c7157149e84f79a85326691352b2a8",
       "IPY_MODEL_0fca71f0ec744dee823d449400815b86"
      ],
      "layout": "IPY_MODEL_0929e0ee656f4ade8f5af724746dfab2"
     }
    },
    "b15bce8e8b4748958b0799ea3a96e692": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_33ef3d3746f74453850b1ee475763ebe",
      "placeholder": "​",
      "style": "IPY_MODEL_3cf390bba16d4d199979678ede175b13",
      "value": " 5000/5000 [00:45&lt;00:00, 110.81it/s]"
     }
    },
    "dc0ee376dff14a96a46a044d27ed7195": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e7ed4b2db0bd4401bf0c01d40944a9f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e7ff3ddb815244a59883f9261d1d5ad6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed35a8718abb464d9fb0776874487e4c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e7ff3ddb815244a59883f9261d1d5ad6",
      "max": 5000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0445ffb9d12e4e8bab8b139ae4e428e4",
      "value": 5000
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

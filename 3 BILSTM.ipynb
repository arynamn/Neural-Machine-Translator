{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54ggsIRvpNvx"
   },
   "source": [
    "## ENCODER DECODER NETWORK\n",
    "\n",
    "AND TEACHER FORCING\n",
    "\n",
    "**References:**\n",
    "\n",
    "Tutorials Given in Competition Document : [Competetion Link](https://docs.google.com/document/d/1p74wG-bECCgbpyq5x_x2QJrf5RSf9FnMLGSAiyUkHLo/edit)\n",
    "\n",
    "PyTorch NMT Tutorial : [Pytorch NMT](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html)\n",
    "\n",
    "Github Page : To understand batch Processing in PyTorch [Github Pengyuchen](https://github.com/pengyuchen/PyTorch-Batch-Seq2seq)\n",
    "\n",
    "Referred Few Stackoverflow Links for few Regex examples and for some bugs.\n",
    "\n",
    "The whole code is divided into two sections:\n",
    "a)  Functions containing all required procedures b) Execution : Using the function . Expand or Collapse to view each sections and subsections.\n",
    "\n",
    "Observations :\n",
    "1.   Using the default learning models work better in Adam.\n",
    "2.   Training in epochs of 20 20 to avoid failure of timeouts.\n",
    "3.   Saving the models is not working. Due to randomness everywhere. Language Word2index and index2word gets mapped to different word everytime. So all randomness need to be removed for saving and reusing the models.\n",
    "\n",
    "\n",
    "NOTE : Change the directory location with respect to google drive location where the data is stored and EXPAND/COLLAPSE Section for the code.\n",
    "\n",
    "No package other than the specified packages are imported\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "egXXQZ_xs9j8",
    "outputId": "79461866-007c-4a6b-dcff-b87d7e0d1d5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Fk01dwzbikwY"
   },
   "outputs": [],
   "source": [
    "location = r\"/content/drive/My Drive/Files/\"                  \n",
    "INDIC_NLP_LIB_HOME = location + \"indic_nlp_library\"\n",
    "INDIC_NLP_RESOURCES = location + \"indic_nlp_resources\"\n",
    "data_location        = location + 'NMT/'                   \n",
    "model_location       = location + 'NMT/NMT_BILSTM/' \n",
    "weekly_data_location = location + 'NMT/Weekly Data/Week3/hindistatements.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YkqUlmpnCNw-"
   },
   "source": [
    "### LIBRARIES  -\n",
    "This subsection contains importing various libraries. Download or clone the indic nlp library and resources to your drive. And change the location accordingly.\n",
    "Also google colab does not have morfessor and uses old version of nltk. So needed to update/install those two packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "j9GYWzxIvQLf"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'{}'.format(INDIC_NLP_LIB_HOME))\n",
    "from indicnlp import common\n",
    "common.set_resources_path(INDIC_NLP_RESOURCES)\n",
    "from indicnlp import loader\n",
    "loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6sFoIG0IL5Gu",
    "outputId": "da5d03f1-bcfc-4810-cc87-6d39498dfa81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Morfessor\n",
      "  Downloading https://files.pythonhosted.org/packages/39/e6/7afea30be2ee4d29ce9de0fa53acbb033163615f849515c0b1956ad074ee/Morfessor-2.0.6-py3-none-any.whl\n",
      "Installing collected packages: Morfessor\n",
      "Successfully installed Morfessor-2.0.6\n"
     ]
    }
   ],
   "source": [
    "!pip install Morfessor\n",
    "import csv\n",
    "import re\n",
    "import string\n",
    "import spacy\n",
    "import tqdm.notebook as tq\n",
    "nlpen = spacy.load(\"en_core_web_sm\")\n",
    "import random\n",
    "import pickle\n",
    "from indicnlp.tokenize import sentence_tokenize\n",
    "from indicnlp.tokenize import indic_tokenize\n",
    "from indicnlp.transliterate.unicode_transliterate import UnicodeIndicTransliterator\n",
    "from indicnlp.transliterate.unicode_transliterate import ItransTransliterator\n",
    "from indicnlp.normalize.indic_normalize import IndicNormalizerFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9nwNgyjxBGwb",
    "outputId": "e73480a3-ac0c-438d-8d8d-deab84190992"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/37/9532ddd4b1bbb619333d5708aaad9bf1742f051a664c3c6fa6632a105fd8/nltk-3.6.2-py3-none-any.whl (1.5MB)\n",
      "\r",
      "\u001b[K     |▎                               | 10kB 20.0MB/s eta 0:00:01\r",
      "\u001b[K     |▌                               | 20kB 27.3MB/s eta 0:00:01\r",
      "\u001b[K     |▊                               | 30kB 21.9MB/s eta 0:00:01\r",
      "\u001b[K     |█                               | 40kB 19.4MB/s eta 0:00:01\r",
      "\u001b[K     |█▏                              | 51kB 21.5MB/s eta 0:00:01\r",
      "\u001b[K     |█▍                              | 61kB 16.3MB/s eta 0:00:01\r",
      "\u001b[K     |█▋                              | 71kB 15.8MB/s eta 0:00:01\r",
      "\u001b[K     |█▉                              | 81kB 15.3MB/s eta 0:00:01\r",
      "\u001b[K     |██                              | 92kB 14.8MB/s eta 0:00:01\r",
      "\u001b[K     |██▎                             | 102kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |██▌                             | 112kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |██▊                             | 122kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 133kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |███▏                            | 143kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |███▍                            | 153kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |███▋                            | 163kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |███▉                            | 174kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 184kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |████▎                           | 194kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |████▌                           | 204kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |████▊                           | 215kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████                           | 225kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████▏                          | 235kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████▍                          | 245kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████▋                          | 256kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████▉                          | 266kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 276kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████▎                         | 286kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████▌                         | 296kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████▊                         | 307kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 317kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████▏                        | 327kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████▍                        | 337kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████▊                        | 348kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 358kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████▏                       | 368kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████▍                       | 378kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████▋                       | 389kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████▉                       | 399kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 409kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▎                      | 419kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▌                      | 430kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▊                      | 440kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 450kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▏                     | 460kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▍                     | 471kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▋                     | 481kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▉                     | 491kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 501kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▎                    | 512kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▌                    | 522kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▊                    | 532kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 542kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▏                   | 552kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▍                   | 563kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▋                   | 573kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▉                   | 583kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 593kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▎                  | 604kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▌                  | 614kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▊                  | 624kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 634kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▏                 | 645kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▍                 | 655kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▋                 | 665kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▉                 | 675kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▏                | 686kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▍                | 696kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▋                | 706kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▉                | 716kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████                | 727kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▎               | 737kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▌               | 747kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▊               | 757kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 768kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▏              | 778kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▍              | 788kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▋              | 798kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▉              | 808kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 819kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▎             | 829kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▌             | 839kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▊             | 849kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 860kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▏            | 870kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▍            | 880kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▋            | 890kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▉            | 901kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 911kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▎           | 921kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▌           | 931kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▊           | 942kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 952kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▏          | 962kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▍          | 972kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▋          | 983kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▉          | 993kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 1.0MB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▎         | 1.0MB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▌         | 1.0MB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▉         | 1.0MB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 1.0MB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▎        | 1.1MB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▌        | 1.1MB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▊        | 1.1MB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 1.1MB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▏       | 1.1MB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▍       | 1.1MB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▋       | 1.1MB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▉       | 1.1MB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 1.1MB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▎      | 1.1MB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▌      | 1.2MB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▊      | 1.2MB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 1.2MB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▏     | 1.2MB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▍     | 1.2MB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▋     | 1.2MB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▉     | 1.2MB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████     | 1.2MB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▎    | 1.2MB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▌    | 1.2MB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▊    | 1.3MB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████    | 1.3MB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▏   | 1.3MB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▍   | 1.3MB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▋   | 1.3MB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▉   | 1.3MB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 1.3MB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▎  | 1.3MB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▌  | 1.3MB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▊  | 1.4MB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 1.4MB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▎ | 1.4MB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▌ | 1.4MB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▊ | 1.4MB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████ | 1.4MB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▏| 1.4MB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▍| 1.4MB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▋| 1.4MB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▉| 1.4MB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 1.5MB 15.2MB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.41.1)\n",
      "Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.7/dist-packages (from nltk) (2019.12.20)\n",
      "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
      "Installing collected packages: nltk\n",
      "  Found existing installation: nltk 3.2.5\n",
      "    Uninstalling nltk-3.2.5:\n",
      "      Successfully uninstalled nltk-3.2.5\n",
      "Successfully installed nltk-3.6.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "!pip install -U nltk\n",
    "import nltk\n",
    "import sys\n",
    "nltk.download('wordnet')\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.meteor_score import single_meteor_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "X8EkUi-1oQQU"
   },
   "outputs": [],
   "source": [
    "def read_csv(location, file_type):\n",
    "    cFile = open(location) \n",
    "    cReader = csv.reader(cFile, delimiter=',')\n",
    "    header = next(cReader)\n",
    "    if( file_type == 'train'):\n",
    "        df = {}\n",
    "        df['hindi'] = []\n",
    "        df['english'] = []\n",
    "        for t in cReader:\n",
    "            df['hindi'].append(t[1])\n",
    "            df['english'].append(t[2])\n",
    "    elif( file_type == 'weekly' ):\n",
    "        df = {}\n",
    "        df['hindi'] = []\n",
    "        for t in cReader:\n",
    "            df['hindi'].append(t[2])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "5Q6gO_hZoRCY"
   },
   "outputs": [],
   "source": [
    "def train_test_split(dataset, test_split_percentage):\n",
    "\n",
    "    total_len   = len(dataset)\n",
    "    total_index = list(range(total_len))\n",
    "    test_index = list( total_index[: int(test_split_percentage*total_len)] )\n",
    "    train_index  = list( total_index[int(test_split_percentage*total_len) : ] )\n",
    "    #np.random.shuffle(test_index)\n",
    "    #np.random.shuffle(train_index)\n",
    "    index = { 'train' : train_index, 'test' : test_index}\n",
    "    train_df = [ dataset[i] for i in train_index ]\n",
    "    test_df  = [ dataset[i] for i in test_index ]\n",
    "    return index, train_df, test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eOV8__452nrJ"
   },
   "source": [
    "### TEXT PROCESSING\n",
    "This subsection contains processing of english and hindi sentences.\n",
    "Since processing the 1 Lakh text pairs takes a lot of time. Instead of doing same thing again and again. I have stored the processed texts and token using pickle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "8s4-n71ApEaD"
   },
   "outputs": [],
   "source": [
    "english_nums = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "hindi_nums =   ['०', '१', '२', '३', '४', '५', '६', '७', '८', '९']\n",
    "\n",
    "def clean_string( instr ):\n",
    "    instr = instr.lower()\n",
    "    instr = instr.replace(u'[', ' ')\n",
    "    instr = instr.replace(u']', ' ')\n",
    "    instr = instr.replace(u'{', ' ')\n",
    "    instr = instr.replace(u'}', ' ')\n",
    "    instr = instr.replace(u'(', ' ')\n",
    "    instr = instr.replace(u')', ' ')\n",
    "    instr = instr.replace(u'...', ' ')\n",
    "    instr = instr.replace(u'..', ' ')\n",
    "    instr = instr.replace(u'-', ' ')\n",
    "    instr = instr.replace(u',', ' ')\n",
    "    instr = instr.replace(u'\"', ' ')\n",
    "    instr = re.sub(' +',' ', instr)\n",
    "    return instr\n",
    "  \n",
    "def preprocess_hindi( instr ):\n",
    "    factory    = IndicNormalizerFactory()\n",
    "    normalizer = factory.get_normalizer(\"hi\",remove_nuktas=True)\n",
    "    instr      = normalizer.normalize(instr)\n",
    "\n",
    "    instr      = clean_string( instr )\n",
    "    #instr = instr.replace(u'॥', '')\n",
    "    for nums in hindi_nums:\n",
    "        instr    = instr.replace(nums, nums + ' ')\n",
    "\n",
    "    instr      = ItransTransliterator.from_itrans( instr , 'hi')  \n",
    "    instr      = re.sub(' +',' ', instr)\n",
    "    instr      = ItransTransliterator.from_itrans( instr , 'hi')\n",
    "    instr      = instr.strip() #sentence_tokenize.sentence_split(instr, lang='hi')\n",
    "    \n",
    "    return instr\n",
    "\n",
    "def preprocess_english( instr ):\n",
    "    instr = clean_string(instr)\n",
    "\n",
    "    instr = instr.replace(\"’\", \"'\")\n",
    "    instr = instr.replace(\"n\\'t\", \" not\")\n",
    "    instr = instr.replace(\"'re\" , \" are\")\n",
    "    instr = instr.replace(\"'ve\" , \" have\")\n",
    "    instr = instr.replace(\"'s\"  , \" is\")\n",
    "    instr = instr.replace(\"'ll\" , \" will\")\n",
    "    instr = instr.replace(\"'m\" , \" am\")\n",
    "    #instr = re.sub(r'[^\\w\\s\\\\d]' , \" \" , instr)\n",
    "    #instr = re.sub(r'[\\d]' , ' ' , instr)\n",
    "\n",
    "    for nums in english_nums:\n",
    "        instr    = instr.replace(nums, nums + ' ')\n",
    "    instr = re.sub(' +',' ', instr)\n",
    "    instr = instr.strip()\n",
    "\n",
    "    return instr\n",
    "\n",
    "def get_hindi_tokens(sentence):\n",
    "    return indic_tokenize.trivial_tokenize(sentence)\n",
    "\n",
    "def get_english_tokens(sentence):\n",
    "    tokens = []\n",
    "    tokstr = nlpen(sentence)\n",
    "    for token in tokstr:\n",
    "        tokens.append(token.text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "7xMHlxgWiAEk"
   },
   "outputs": [],
   "source": [
    "# Load_From_file =\n",
    "#   -1   : Process the texts and store/dump the files into the location\n",
    "#    0   : Process the texts and do not store the files\n",
    "#    1   : Directly load the processed text from the location\n",
    "\n",
    "def process_pairs(df, load_from_file = 0, location = ''):\n",
    "    if( load_from_file == 1):\n",
    "        with open(location + r'pairs.pickle', 'rb') as handle:\n",
    "            pairs = pickle.load(handle)\n",
    "        with open(location + r'pairs_tokens.pickle', 'rb') as handle:\n",
    "            pairs_tokens = pickle.load(handle)\n",
    "        return pairs, pairs_tokens\n",
    "    else:\n",
    "        pairs = []\n",
    "        pairs_tokens = []\n",
    "        for i in tq.tqdm( range( len(df['hindi']) )):\n",
    "            hinsen  = df['hindi'][i]\n",
    "            hsent   = preprocess_hindi( hinsen )\n",
    "            htokens = get_hindi_tokens(hsent)\n",
    "\n",
    "            engsen  = df['english'][i]\n",
    "            esent   = preprocess_english( engsen )\n",
    "            etokens = get_english_tokens(esent)\n",
    "\n",
    "            pairs.append( [hsent, esent] )\n",
    "            pairs_tokens.append( [htokens, etokens] )\n",
    "\n",
    "        if( load_from_file == -1):\n",
    "            with open(location + r'pairs.pickle', 'wb') as handle:\n",
    "                pickle.dump(pairs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            with open(location + r'pairs_tokens.pickle', 'wb') as handle:\n",
    "                pickle.dump(pairs_tokens, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        return pairs, pairs_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JfKCjT9t2Uce"
   },
   "source": [
    "### LANGUAGE\n",
    "This subsection contains the class 'Laguage' which stores all the token and its equivalent index. This subsection also contains functions to convert a sentence to a tensor.\n",
    "\n",
    "This subsection is referred from pytorch tutorial on NMT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "pkvN-M2T2OwM"
   },
   "outputs": [],
   "source": [
    "START_TOKEN = 0\n",
    "END_TOKEN = 1\n",
    "PAD_TOKEN = 2\n",
    "UNK_TOKEN = 3\n",
    "\n",
    "class Language:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {}\n",
    "        self.num_words = 4\n",
    "        self.word2index['START_TOKEN'] = START_TOKEN\n",
    "        self.word2index['END_TOKEN']   = END_TOKEN\n",
    "        self.word2index['PAD_TOKEN']   = PAD_TOKEN\n",
    "        self.word2index['UNK_TOKEN']   = UNK_TOKEN\n",
    "        self.index2word[START_TOKEN] = 'START_TOKEN'\n",
    "        self.index2word[END_TOKEN] = 'END_TOKEN'\n",
    "        self.index2word[PAD_TOKEN] = 'PAD_TOKEN'\n",
    "        self.index2word[UNK_TOKEN] = 'UNK_TOKEN'\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word in self.word2count:\n",
    "            self.word2count[word] = self.word2count[word] + 1\n",
    "        else:\n",
    "            self.word2count[word] = 1\n",
    "            #self.word2index[word] = self.num_words\n",
    "            #self.index2word[self.num_words] = word\n",
    "            self.num_words = self.num_words + 1\n",
    "    \n",
    "    def addSentence(self, sentence_tokens):\n",
    "        for word in sentence_tokens:\n",
    "            self.addWord(word)\n",
    "    \n",
    "    def filter_words(self):\n",
    "        self.num_words = 4\n",
    "        for word in self.word2count:\n",
    "            if( self.word2count[word] != 1):\n",
    "                self.word2index[word] = self.num_words\n",
    "                self.index2word[self.num_words] = word\n",
    "                self.num_words = self.num_words + 1\n",
    "\n",
    "\n",
    "def generate_language( pairs_tokens ):\n",
    "    hindi   = Language('hindi')\n",
    "    english = Language('english')\n",
    "    for i in tq.tqdm( range(len(pairs_tokens)) ):\n",
    "        hindi.addSentence(pairs_tokens[i][0])\n",
    "        english.addSentence(pairs_tokens[i][1])\n",
    "    hindi.filter_words()\n",
    "    english.filter_words()\n",
    "    return hindi, english"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-IHLiyXjNOM5"
   },
   "source": [
    "PROCESS TEXT TO TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "_KiyGuO121HM"
   },
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, tokens, max_length):\n",
    "    indexes = []\n",
    "    indexes.append(START_TOKEN)\n",
    "    for word in tokens:\n",
    "        if word in lang.word2index.keys():\n",
    "            indexes.append( lang.word2index[word] )\n",
    "        else:\n",
    "            indexes.append( lang.word2index['UNK_TOKEN'] )\n",
    "    indexes = indexes[0:max_length-1]\n",
    "    indexes.append(END_TOKEN)\n",
    "    indexes.extend( [PAD_TOKEN]*( max_length - len(indexes)))\n",
    "    return indexes\n",
    "\n",
    "def tensorFromSentence(lang, sentence, max_length):\n",
    "    indexes = indexesFromSentence(lang, sentence, max_length)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device)\n",
    "\n",
    "def tensorsFromPair(pairs, input_lang, output_lang, max_length):\n",
    "    res_pairs = []\n",
    "    for pair in pairs:\n",
    "        input_tensor  = tensorFromSentence(input_lang, pair[0], max_length)\n",
    "        target_tensor = tensorFromSentence(output_lang, pair[1], max_length)\n",
    "        res_pairs.append( (input_tensor, target_tensor) )\n",
    "    return res_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZTFkvFITItSA"
   },
   "source": [
    "### NEURAL MACHINE TRANSLATOR\n",
    "This subjection contains 3 main classes Encoder , Decoder and an seq2seq which merge the two encoder and decoder.\n",
    "It also contains a function to train, use and evaluate the seq2seq model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S7q0i3jQIYYy"
   },
   "source": [
    "ENCODER and DECODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Ibd0funOIVy-"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embed_size, hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_size, embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, bidirectional = True, num_layers = 2, dropout = 0.2)\n",
    "        #self.fc_hidden = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        #self.fc_cell = nn.Linear(hidden_size * 2, hidden_size)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # input.shape :    [Sentence Length, Batch Size]\n",
    "        # embedded.shape : [Sentence Length, Batch Size, Embedding Dimension]\n",
    "        # output.shape :   [Sentence Length, Batch Size, Hidden Size]\n",
    "        # hidden.shape :   [Layers = 2*2 , Batch Size, Hidden Size]\n",
    "        # cell.shape   :   [Layers = 2*2 , Batch Size, Hidden Size]\n",
    "\n",
    "        embedded = self.embedding(input)\n",
    "        output, (hidden, cell) = self.lstm(embedded)\n",
    "\n",
    "        return output, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "bvKT-boqIb-L"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_size, embed_size, hidden_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, embed_size)\n",
    "        self.lstm   = nn.LSTM(embed_size, hidden_size, bidirectional = True, num_layers = 2, dropout = 0.2)\n",
    "        self.dense  = nn.Linear(hidden_size*2, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, target, hidden, cell):\n",
    "        # target.shape :   [Batch Size]\n",
    "        # target.shape :   [1, Batch Size] after unsqueezing\n",
    "        # embed.shape  :   [1, Batch Size, Embedding Size]\n",
    "        # output.shape :   [1, Batch Size, Hidden Size] before squeezing\n",
    "        # hidden.shape :   [Layers = 2, Batch Size, Hidden Size]\n",
    "        # cell.shape   :   [Layers = 2, Batch Size, Hidden Size]\n",
    "        # preds.shape  :   [Batch Size, Output_Vocabulary_Size]\n",
    "\n",
    "        \n",
    "        target = target.unsqueeze(0)\n",
    "        embed = self.embedding(target)\n",
    "        #embed = F.relu(embed)\n",
    "        output, (hidden, cell) = self.lstm(embed, (hidden, cell) )\n",
    "        preds = self.dense(output[0])\n",
    "        #preds = F.relu(preds)\n",
    "        preds = self.softmax(preds)\n",
    "\n",
    "        return preds, hidden, cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WcrhHwoc03gH"
   },
   "source": [
    "SEQUENCE 2 SEQUENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "2XOqKk6z02WY"
   },
   "outputs": [],
   "source": [
    "class seq2seq(nn.Module):\n",
    "    def __init__(self, input_size, output_size, embed_size, hidden_size, max_length):\n",
    "        super(seq2seq, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.embed_size = embed_size\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.encoder = Encoder(input_size, embed_size, hidden_size).to(device)\n",
    "        self.decoder = Decoder(output_size, embed_size, hidden_size).to(device)\n",
    "\n",
    "    def forward(self, src, target , teacher_forcing = 0.5):\n",
    "        # If teacher forcing is set to 0.5, it will use true outputs half the time for\n",
    "        # next input to decoder and use the predicted output as input\n",
    "        # If teacher forcing is 0, it will always use previous output as input to decoder.\n",
    "\n",
    "        # src.shape    = [Input Sentence Length, Batch Size]\n",
    "        # target.shape = [Output Sentence Length, Batch Size]\n",
    "        # decoder_output.shape = [ Output Sentence Length, Batch Size, ]\n",
    "        # Encode the Source Sentence; Decode the tokens one by one.\n",
    "\n",
    "\n",
    "        batch_size, target_vocab_size = src.shape[1], self.output_size\n",
    "        outputs = torch.zeros(self.max_length, batch_size, target_vocab_size).to(device)\n",
    "        _, hidden, cell = self.encoder(src)\n",
    "        dinput = src[0,:]\n",
    "        for index in range(1, self.max_length):\n",
    "            output, hidden, cell = self.decoder(dinput, hidden, cell)\n",
    "            if random.random() < teacher_forcing:\n",
    "                dinput = target[index]  \n",
    "            else:\n",
    "                dinput = output.argmax(1)\n",
    "            outputs[index] = output\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "W6AEQ77JLZta"
   },
   "outputs": [],
   "source": [
    "# Set model in training mode to activate dropouts\n",
    "# Transpose the text tokens to adjust to pytorch\n",
    "# Forward Pass on Encoder-Decoder\n",
    "# Optimize network\n",
    "def train( model, opt, lossfn, train_loader, r_epoch, save_model=0):\n",
    "    model.train()\n",
    "    history = []\n",
    "    num_batches = len(train_loader)\n",
    "    for epoch in range(r_epoch[0], r_epoch[1]):\n",
    "        epoch_loss = 0\n",
    "        for inS, outS in tq.tqdm( train_loader ):\n",
    "            opt.zero_grad()\n",
    "            loss = 0\n",
    "\n",
    "            inS =  inS.transpose(0, 1)\n",
    "            outS = outS.transpose(0, 1)\n",
    "            predoutS = model(inS, target = outS)\n",
    "            outS     = outS[1:].reshape(-1)       # Reshape outputs\n",
    "            predoutS = predoutS[1:].reshape(-1, predoutS.shape[-1])\n",
    "\n",
    "            loss = lossfn(predoutS, outS)         # Compute Loss\n",
    "            loss.backward()                       # Propagate Loss To the Netowork\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1)  # Gradient Clipping\n",
    "            opt.step()                            # Update the weights\n",
    "            epoch_loss = epoch_loss + loss.item()\n",
    "            \n",
    "\n",
    "        print(' Epoch : ', epoch , '   loss  : ', epoch_loss / num_batches )\n",
    "        history.append(epoch_loss / num_batches)\n",
    "\n",
    "        if( save_model == 1):\n",
    "            torch.save(model.state_dict(), model_location + 'bilstm_dict_' + str(epoch) )\n",
    "            if( (epoch+1)%20 == 0):\n",
    "                torch.save(model, model_location + 'bilstm_' +  str(epoch) )\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "4nNNUI8Dt_tM"
   },
   "outputs": [],
   "source": [
    "# Set model to evaluation model to disable dropout layer\n",
    "# get Tensor from Sentence and adjust it to size [Sequence Length, Max Length = 1]\n",
    "def make_sentence(tokens):\n",
    "    str = ''\n",
    "    for x in tokens:\n",
    "        if x is 'UNK_TOKEN':\n",
    "            str = str + ' ' + '<UNK>'\n",
    "        if x not in ['START_TOKEN', 'END_TOKEN', 'PAD_TOKEN']:\n",
    "            str = str + ' ' + x\n",
    "    return re.sub('(?<=\\d)+ (?=\\d)+', '', str)[1:]\n",
    "\n",
    "def translate(model, sentence, input_lang, output_lang, max_length):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input = tensorFromSentence( input_lang, sentence, max_length= max_length)\n",
    "        input = torch.transpose( input.unsqueeze(0) , 0 , 1)\n",
    "        output = model(input, target=None, teacher_forcing = 0)\n",
    "        dec_words = []\n",
    "        for x in output.squeeze():\n",
    "            i = x.argmax(0)\n",
    "            dec_words.append( output_lang.index2word[ i.item() ] )\n",
    "            if(i.item() == END_TOKEN ):\n",
    "                break\n",
    "    return make_sentence( dec_words )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NXoK92_1o4Ez"
   },
   "source": [
    "PERFORMANCE EVALUATION\n",
    "Evaluation Script Modified to give Bleu and Meteor Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "hvQPdkMtov-L"
   },
   "outputs": [],
   "source": [
    "def get_bleu_score(model, pairs, input_lang, output_lang, max_length):\n",
    "    total_num = len(pairs)\n",
    "    total_bleu_scores = 0\n",
    "    total_meteor_scores = 0\n",
    "    \n",
    "    for i in tq.tqdm( range(total_num) ):\n",
    "        output    = translate(model, pairs[i][0], input_lang, output_lang, max_length)\n",
    "        original  = make_sentence(pairs[i][1])\n",
    "        total_bleu_scores   += sentence_bleu([output.split(\" \")], original.split(\" \"))\n",
    "        total_meteor_scores += single_meteor_score(output, original)\n",
    "\n",
    "    bleu_result = total_bleu_scores/total_num\n",
    "    meteor_result = total_meteor_scores/total_num\n",
    "    \n",
    "    print()\n",
    "    print(\"BLEU score: \",bleu_result)\n",
    "    print(\"METEOR score: \",meteor_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SFtWOWbbsQwS"
   },
   "source": [
    "# EXECUTION\n",
    "Executing the whole process.\n",
    "\n",
    "\n",
    "1.   Read the training data\n",
    "2.   Process all sentences( english and hindi)\n",
    "3.   Generate Language ( word2index and index2word)\n",
    "4.   Prepare tensors for all tokens.\n",
    "5.   Create the seq2seq model and train the model\n",
    "6.   Evaluate the performance\n",
    "7.   Use the model for weekly translation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OWWqvluwXPMG"
   },
   "source": [
    "READ AND PROCESS FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Bi-YuD2xMLss"
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 32\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183,
     "referenced_widgets": [
      "f116e26365984032bf02d34b1feb2451",
      "304d9f07a9534d1fbc185b47f6902fdf",
      "e573b365b578484e97b3522c855509b3",
      "0bef926a7e364c659177fc4b63deb41e",
      "be072826872d4c81b39d3756ef423328",
      "783ec812cbb04227b1df557e08f8f221",
      "5156141d6b064357a965b6026b2d8086",
      "f7e6933df4e5471cab052e70943cd5f1"
     ]
    },
    "id": "KF2PDfoyrush",
    "outputId": "30f3de1b-3840-4ec5-b7f6-a54de1954bb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Training Data ... Done\n",
      "Processing Strings ... Done\n",
      "Splitting Dataset ... Done\n",
      "Preparing Language Word2vectors and inverse ... "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f116e26365984032bf02d34b1feb2451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=102322.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done, Hindi Token Count :  21104   English Token Count :  18988\n",
      "Preparing Tensors ... Done\n",
      "Preparing Dataloaders ... Done\n"
     ]
    }
   ],
   "source": [
    "print('Reading Training Data ... ', end = '')\n",
    "df = read_csv(data_location + 'train.csv', 'train')\n",
    "print('Done')\n",
    "\n",
    "print('Processing Strings ... ', end = '')\n",
    "pairs, tokens = process_pairs(df, load_from_file=1, location = data_location + 'DataPairs/')\n",
    "print('Done')\n",
    "\n",
    "print('Splitting Dataset ... ', end = '')\n",
    "index, train_tokens, test_tokens = train_test_split(tokens,  0.2)\n",
    "print('Done')\n",
    "\n",
    "print('Preparing Language Word2vectors and inverse ... ', end = '')\n",
    "# Generate Langauge Input and Output\n",
    "hindi, english = generate_language(tokens)\n",
    "print('Done, Hindi Token Count : ', hindi.num_words, '  English Token Count : ', english.num_words)\n",
    "\n",
    "print('Preparing Tensors ... ', end = '')\n",
    "# Get Tensors for tokens and create Dataloaders\n",
    "train_tensors = tensorsFromPair(train_tokens, hindi, english, MAX_LENGTH)\n",
    "test_tensors = tensorsFromPair(test_tokens, hindi, english, MAX_LENGTH)\n",
    "print('Done')\n",
    "\n",
    "print('Preparing Dataloaders ... ', end = '')\n",
    "train_loader = torch.utils.data.DataLoader(train_tensors, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = torch.utils.data.DataLoader(test_tensors, batch_size=batch_size, shuffle=True)\n",
    "pretrainloader = torch.utils.data.DataLoader(train_tensors[0:batch_size], batch_size=batch_size, shuffle=True)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D3zinlYyXay_"
   },
   "source": [
    "TRAIN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pHcfyAnfZ_TE",
    "outputId": "62baf2ac-86cf-4e8c-d5e9-ba8dc909f1c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialising Parameters\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FxPgfDvYYr30",
    "outputId": "51039c20-939d-4c63-d704-955ff4b35771"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialising Parameters\n",
      "Creating Models ...  Done\n",
      "Loading Pretrained Weights .. :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "seq2seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(21105, 300)\n",
       "    (lstm): LSTM(300, 512, num_layers=2, dropout=0.2, bidirectional=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(18989, 300)\n",
       "    (lstm): LSTM(300, 512, num_layers=2, dropout=0.2, bidirectional=True)\n",
       "    (dense): Linear(in_features=1024, out_features=18989, bias=True)\n",
       "    (softmax): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Parameters\n",
    "print('Initialising Parameters')\n",
    "hidden_size = 512\n",
    "input_vocab_size = hindi.num_words + 1\n",
    "output_vocab_size = english.num_words + 1\n",
    "embedding_dim = 300\n",
    "epochs = 20\n",
    "\n",
    "\n",
    "#Generate Model, optimizer, lossfn\n",
    "print('Creating Models ... ', end = ' ')\n",
    "model = seq2seq(input_vocab_size, output_vocab_size , embedding_dim, hidden_size, MAX_LENGTH)\n",
    "optimizer = optim.Adam( model.parameters())\n",
    "lossfn = nn.NLLLoss(ignore_index=PAD_TOKEN)\n",
    "print('Done')\n",
    "\n",
    "#load_model weights if available\n",
    "load_model = 1\n",
    "if(load_model==1):\n",
    "    print('Loading Pretrained Weights .. :')\n",
    "    model.load_state_dict( torch.load(model_location + 'bilstm_dict_40'))\n",
    "model.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 99,
     "referenced_widgets": [
      "b7fb61ac9ef84a4b821539a940e51232",
      "4db8d97078b84d25806902b3ae5b518d",
      "3c10ac620b194cadbf66cb3f72d430b0",
      "5b5a874e7bb14fe2b00c5aa2da9f4899",
      "1010bb99da9a4848addf63c7986f1b3e",
      "37a6e4e072514ab9be8f1000753c8dad",
      "fa74b7961bb7401183fa8bc5ee76253b",
      "eb48d2266364405e9584e487ff253db9"
     ]
    },
    "id": "Fe6MoRmqaP3a",
    "outputId": "73067a76-c910-49f7-b63f-c805eb91b105"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7fb61ac9ef84a4b821539a940e51232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch :  0    loss  :  9.8493070602417\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[9.8493070602417]"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pretrain to Overfit Model on single batch\n",
    "train(model, optimizer, lossfn, pretrainloader, (0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PMrSrACYCMGs"
   },
   "outputs": [],
   "source": [
    "#save_losses\n",
    "Losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "e2052c2e8ba44bb5a5bd9ca5bdd0d050",
      "5deaf4cd6bee4f758c887e6a92b2c5ff",
      "33c4c6fd6c2e494eb226307030c67a03",
      "bd74a28734454ca188137b1c937d63e3",
      "51481098b3254e5ab96014123c9fdb8d",
      "ffee7182204c45dfa228abb8b5ffbaf2",
      "991d9b7d14814fc2af5a5312abde4a4a",
      "6231cf14eacb437fa818ea377b904585"
     ]
    },
    "id": "VEG2GbQDalME",
    "outputId": "045565ef-3ea2-49d5-dfaa-999814f71589"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2052c2e8ba44bb5a5bd9ca5bdd0d050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=320.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch :  0    loss  :  5.944774422049522\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.944774422049522]"
      ]
     },
     "execution_count": 0,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final Train on all Training Data Set, # Append the losses\n",
    "history = train(model, optimizer, lossfn, train_loader, (0 , 0+1), save_model = 1)\n",
    "Losses.extend(history)\n",
    "Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8pB8ou00rO0J"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SJRl_b4IS6xp"
   },
   "outputs": [],
   "source": [
    "#save Model and its dictionary\n",
    "torch.save(model.state_dict(), model_location + 'bilstm_np_dict_' + str(20+epochs) )\n",
    "torch.save(model, model_location + 'bilstm_np_' + str(20+epochs) )\n",
    "torch.save(model.encoder.state_dict(), model_location + 'bilstm_enc_dict_' + str(20+epochs) )\n",
    "torch.save(model.encoder, model_location + 'bilstm_enc_' + str(20+epochs) )\n",
    "torch.save(model.decoder.state_dict(), model_location + 'bilstm_dec_dict_' + str(20+epochs) )\n",
    "torch.save(model.decoder, model_location + 'bilstm_dec_' + str(20+epochs) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SVuPC0bCTkT7"
   },
   "source": [
    "### USE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 418,
     "referenced_widgets": [
      "b372dbbca82c421e8017797039e5afb0",
      "fcb333b5100347b09616ab2442255642",
      "d64448380458405e9ad8611b57de19b2",
      "e4db66d50f2449478c0c8a34c9ad4488",
      "bbdc835ddfcf419297d6565d432a8a06",
      "4cd12c11c6e04192953c2721cfe17e57",
      "005b53386ebe4196947c9d50c24ebb39",
      "4be68b650fce49509da6db5271c4af89"
     ]
    },
    "id": "lxy6OQrfZc_O",
    "outputId": "9ae8ff4b-54ec-47a4-b0f6-914ff2cb9140"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b372dbbca82c421e8017797039e5afb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20464.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "BLEU score:  0.03419358438943977\n",
      "METEOR score:  0.3032598433153708\n"
     ]
    }
   ],
   "source": [
    "get_bleu_score(model, test_tokens, hindi, english, MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "acTRjUA0bg7l"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wd6jSg0bXg1a"
   },
   "source": [
    "USE MODEL FOR WEEKLY TRANSLATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EmC5MWcQXmbH"
   },
   "outputs": [],
   "source": [
    "week = read_csv(weekly_data_location, file_type='weekly')    # Load weekly data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EAmOtFd2hlU1"
   },
   "outputs": [],
   "source": [
    "# Process sentences\n",
    "week_processed = []\n",
    "for x in  week['hindi']:\n",
    "    t = get_hindi_tokens(preprocess_hindi(x))\n",
    "    week_processed.append(t)\n",
    "\n",
    "# Testing model on single sentence.\n",
    "i = 40\n",
    "print( week_processed[i] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SECCQKz24VFS"
   },
   "outputs": [],
   "source": [
    "translate(model, week_processed[i], hindi, english, MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bEU8-5fi19ET"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DRsRuWQT1i7l"
   },
   "outputs": [],
   "source": [
    "# Translate all weekly sentences\n",
    "translated_texts = []\n",
    "for i in tq.tqdm( range(len(week_processed)) ):\n",
    "  translated_texts.append( translate(model, week_processed[i], hindi, english, MAX_LENGTH) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mDufBeCJXw1f"
   },
   "outputs": [],
   "source": [
    "# Store the translated sentence to txt file\n",
    "with open(data_location + 'Weekly Data/Week3/bilstm40.txt', 'w') as f:\n",
    "    for item in translated_texts:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uGXG3VGnZbxr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "frk9g3E8r8X4"
   },
   "outputs": [],
   "source": [
    "#torch.save( tmodel.state_dict(), model_location + 'gru_dict_100')\n",
    "#torch.save(model, location+ 'gru_enc_dec')\n",
    "\n",
    "#tmodel = torch.load(model_location+ 'gru_100')\n",
    "#tmodel.eval()\n",
    "\n",
    "#tq.tqdm._instances.clear()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "YkqUlmpnCNw-",
    "eOV8__452nrJ",
    "JfKCjT9t2Uce",
    "ZTFkvFITItSA"
   ],
   "name": "NMT_BILSTM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "005b53386ebe4196947c9d50c24ebb39": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0bef926a7e364c659177fc4b63deb41e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f7e6933df4e5471cab052e70943cd5f1",
      "placeholder": "​",
      "style": "IPY_MODEL_5156141d6b064357a965b6026b2d8086",
      "value": " 102322/102322 [00:12&lt;00:00, 8478.89it/s]"
     }
    },
    "1010bb99da9a4848addf63c7986f1b3e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "304d9f07a9534d1fbc185b47f6902fdf": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "33c4c6fd6c2e494eb226307030c67a03": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_991d9b7d14814fc2af5a5312abde4a4a",
      "placeholder": "​",
      "style": "IPY_MODEL_6231cf14eacb437fa818ea377b904585",
      "value": " 3/320 [00:03&lt;05:33,  1.05s/it]"
     }
    },
    "37a6e4e072514ab9be8f1000753c8dad": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "3c10ac620b194cadbf66cb3f72d430b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fa74b7961bb7401183fa8bc5ee76253b",
      "placeholder": "​",
      "style": "IPY_MODEL_eb48d2266364405e9584e487ff253db9",
      "value": " 1/1 [00:04&lt;00:00,  4.80s/it]"
     }
    },
    "4be68b650fce49509da6db5271c4af89": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4cd12c11c6e04192953c2721cfe17e57": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4db8d97078b84d25806902b3ae5b518d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1010bb99da9a4848addf63c7986f1b3e",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_37a6e4e072514ab9be8f1000753c8dad",
      "value": 1
     }
    },
    "51481098b3254e5ab96014123c9fdb8d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5156141d6b064357a965b6026b2d8086": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5b5a874e7bb14fe2b00c5aa2da9f4899": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5deaf4cd6bee4f758c887e6a92b2c5ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "  1%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_51481098b3254e5ab96014123c9fdb8d",
      "max": 320,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ffee7182204c45dfa228abb8b5ffbaf2",
      "value": 3
     }
    },
    "6231cf14eacb437fa818ea377b904585": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "783ec812cbb04227b1df557e08f8f221": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "991d9b7d14814fc2af5a5312abde4a4a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b372dbbca82c421e8017797039e5afb0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d64448380458405e9ad8611b57de19b2",
       "IPY_MODEL_e4db66d50f2449478c0c8a34c9ad4488"
      ],
      "layout": "IPY_MODEL_fcb333b5100347b09616ab2442255642"
     }
    },
    "b7fb61ac9ef84a4b821539a940e51232": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4db8d97078b84d25806902b3ae5b518d",
       "IPY_MODEL_3c10ac620b194cadbf66cb3f72d430b0"
      ],
      "layout": "IPY_MODEL_5b5a874e7bb14fe2b00c5aa2da9f4899"
     }
    },
    "bbdc835ddfcf419297d6565d432a8a06": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "bd74a28734454ca188137b1c937d63e3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "be072826872d4c81b39d3756ef423328": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "d64448380458405e9ad8611b57de19b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4cd12c11c6e04192953c2721cfe17e57",
      "max": 20464,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bbdc835ddfcf419297d6565d432a8a06",
      "value": 20464
     }
    },
    "e2052c2e8ba44bb5a5bd9ca5bdd0d050": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5deaf4cd6bee4f758c887e6a92b2c5ff",
       "IPY_MODEL_33c4c6fd6c2e494eb226307030c67a03"
      ],
      "layout": "IPY_MODEL_bd74a28734454ca188137b1c937d63e3"
     }
    },
    "e4db66d50f2449478c0c8a34c9ad4488": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4be68b650fce49509da6db5271c4af89",
      "placeholder": "​",
      "style": "IPY_MODEL_005b53386ebe4196947c9d50c24ebb39",
      "value": " 20464/20464 [08:45&lt;00:00, 38.95it/s]"
     }
    },
    "e573b365b578484e97b3522c855509b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_783ec812cbb04227b1df557e08f8f221",
      "max": 102322,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_be072826872d4c81b39d3756ef423328",
      "value": 102322
     }
    },
    "eb48d2266364405e9584e487ff253db9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f116e26365984032bf02d34b1feb2451": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e573b365b578484e97b3522c855509b3",
       "IPY_MODEL_0bef926a7e364c659177fc4b63deb41e"
      ],
      "layout": "IPY_MODEL_304d9f07a9534d1fbc185b47f6902fdf"
     }
    },
    "f7e6933df4e5471cab052e70943cd5f1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fa74b7961bb7401183fa8bc5ee76253b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fcb333b5100347b09616ab2442255642": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ffee7182204c45dfa228abb8b5ffbaf2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
